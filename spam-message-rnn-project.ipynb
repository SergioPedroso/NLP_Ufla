{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d800865b",
   "metadata": {},
   "source": [
    "# Spam Message Classification using RNNs (LSTM, Bi-LSTM, GRU)\n",
    "\n",
    "Personal project on natural language processing (NLP) using recurrent neural networks (RNNs). In this notebook, I build and compare deep learning models to classify SMS messages as either *spam* or *ham* (not spam).\n",
    "\n",
    "The main goal here is to practice building models with LSTM, Bi-LSTM, and GRU layers using TensorFlow/Keras, as well as to explore basic text preprocessing and evaluation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658f965",
   "metadata": {},
   "source": [
    "## Problem Overview\n",
    "\n",
    "This project focuses on building RNN-based models for text classification. The goal is to develop models that can detect whether a given SMS message is *spam* or *ham* (not spam), which is a typical binary classification task in NLP.\n",
    "\n",
    "I'll go through the following steps:\n",
    "- Data preprocessing\n",
    "- Tokenization and padding\n",
    "- Building LSTM, Bi-LSTM, and GRU models\n",
    "- Training and evaluation\n",
    "\n",
    "### References\n",
    "- Inspired by: [Text Classification using LSTM, Bi-LSTM, and GRU](https://nzlul.medium.com/the-classification-of-text-messages-using-lstm-bi-lstm-and-gru-f79b207f90ad)\n",
    "- Keras documentation on RNN layers: https://keras.io/api/layers/recurrent_layers/\n",
    "- TensorFlow RNN guide: https://www.tensorflow.org/guide/keras/working_with_rnns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load, explore and plot data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "%matplotlib inline\n",
    "#  Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#  Text pre-processing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#  Modeling\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Embedding, Dropout, GlobalAveragePooling1D, Flatten, SpatialDropout1D, Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Base de dados de mensagens SMS de celulares, publicamente disponível na UCL datasets (https://archive.ics.uci.edu/dataset/228/sms+spam+collection). Pode também ser baixada de https://raw.githubusercontent.com/kenneth-lee-ch/SMS-Spam-Classification/master/spam.csv<br>\n",
    "O dataset contém 5.574 mensagens rotuladas como *spam* ou não *spam* (*ham*).\n",
    "\n",
    "A biblioteca Pandas foi usada para ler e manipular o dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc73240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  read the dataset\n",
    "df = pd.read_csv('./datasets/spam.csv', encoding='ISO-8859-1')\n",
    "#  rename the columns\n",
    "df = df[['v1','v2']]\n",
    "df.rename(columns={'v1':'label', 'v2':'message'}, inplace=True)\n",
    "#  show the first instances\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estatísticas sobre os Dados\n",
    "\n",
    "Exibe um sumário das estatísticas para melhor entender os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c83c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c5c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('label').describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuvem de Palavras\n",
    "\n",
    "Visualiza as palavras mais frequentes em cada classe usando uma nuvem de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_msg  = df.loc[df['label'] == 'ham']\n",
    "spam_msg = df.loc[df['label'] == 'spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f77af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Nuvem de palavras da classe 'ham'\n",
    "ham_msg_text = ' '.join(ham_msg['message'])\n",
    "ham_msg_cloud = WordCloud(width =520, height =260, stopwords = STOPWORDS, max_font_size = 50, background_color = \"black\", colormap = 'Pastel1').generate(ham_msg_text)\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.imshow(ham_msg_cloud, interpolation = 'bilinear')\n",
    "plt.axis('off') #  turn off axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palavras mais frequentes da classe 'ham', de acordo com a nuvem de palavras: now, will, ok, today, Sorry etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicione abaixo um trecho de código para gerar a nuvem de palavras para os textos da classe 'spam'.<br>\n",
    "Depois, verifique as palavras mais frequentes da classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca8af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Nuvem de palavras da classe 'spam'\n",
    "# # #  INICIE O CÓDIGO AQUI # # #  (6 ou mais linhas de código)\n",
    "#  Nuvem de palavras da classe 'ham'\n",
    "spam_msg_text = ' '.join(spam_msg['message'])\n",
    "spam_msg_cloud = WordCloud(width =520, height =260, stopwords = STOPWORDS, max_font_size = 50, background_color = \"black\", colormap = 'Pastel1').generate(spam_msg_text)\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.imshow(spam_msg_cloud, interpolation = 'bilinear')\n",
    "plt.axis('off') #  turn off axis\n",
    "plt.show()\n",
    "# # #  TERMINE O CÓDIGO AQUI # # # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palavras mais frequentes da classe 'spam', de acordo com a nuvem de palavras: FREE, call, URGENT, mobile, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceamento dos Dados\n",
    "\n",
    "Como veremos abaixo, o dataset está muito desbalanceado. Existem muito mais mensagens na classe 'ham' do que na classe 'spam'.<br>\n",
    "O treinamento de modelos de aprendizagem de máquina a partir de datasets muito desbalanceados pode gerar um viés, levando o modelo a predizer a classe mais frequente.<br>\n",
    "\n",
    "Existem algumas abordagens para tratar o problema de dados desbalanceados, dentre elas: escolher métricas de avaliação mais apropriadas, resampling (oversampling and undersampling), Synthetic Minority Oversampling Technique (SMOTE), BalancedBaggingClassifier, Threshold moving.<br>\n",
    "\n",
    "Neste notebook, nós usaremos o método undersampling (subamostragem) para manusear os dados desbalanceados. A técnica consiste em subamostrar a classe majoritária de forma aleatória e uniforme, escolhendo, aproximadamente, o mesmo número de instâncias da classe minoritária. Isso pode potenciamente conduzir a perda de informação, mas se os exemplos da classe majoritária estiverem próximos uns aos outros, esse método pode levar a bons resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d69e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Distribuição das mensagens em 'ham' e 'spam'\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(df.label)\n",
    "plt.title('The distribution of ham and spam messages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  downsample the ham msg\n",
    "ham_msg_df = ham_msg.sample(n = len(spam_msg), random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c333b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_df = pd.concat([ham_msg_df, spam_msg])\n",
    "msg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220fbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffe00c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Nova distribuição\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(msg_df.label)\n",
    "plt.title('The distribution of ham and spam messages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento do Texto\n",
    "\n",
    "Cria duas colunas no *dataframe*: uma para armazenar o comprimento de cada mensagem de texto e outra para armazenar o rótulo da classe convertido para um valor numérico (0: ham, 1: spam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get length column for each text\n",
    "msg_df['text_length'] = msg_df['message'].apply(len)\n",
    "#  Get the converted numeric label of the data\n",
    "msg_df['msg_type'] = msg_df['label'].map({'ham':0, 'spam':1})\n",
    "msg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão dos Dados em Treino e Teste\n",
    "\n",
    "Os dados são divididos, aletatoriamente, em 80% para treino e 20% para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05dbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(msg_df['message'], msg_df['msg_type'], test_size=0.2, random_state=434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41f018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização\n",
    "\n",
    "Os textos das mensagens precisam ser convertidos para uma representação numérica, para que o modelo possa entendê-los.\n",
    "\n",
    "A API Tokenizer do TensorFlow divide as sentenças em palavras e as codifica em números inteiros.\n",
    "\n",
    "O Tokenizer executará os seguintes passos de pré-processamento: tokeniza a nível de palavras, remove os termos de pontuação, converte todas as palavras para minúsculas, converte todas as palavras para números inteiros. Os seguintes parâmetros foram definidos:\n",
    "- num_words: número de palavras únicas (vocabulário)\n",
    "- oov_token: token usado para substituir palavras que não estiverem no vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Defining pre-processing parameters\n",
    "max_len = 50 \n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>' #  out of vocabulary token\n",
    "vocab_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7513801",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, \n",
    "                      char_level = False,\n",
    "                      oov_token = oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd8f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get the word_index\n",
    "word_index = tokenizer.word_index\n",
    "total_words = len(word_index)\n",
    "total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, cada sentença é representada por uma sequência de números usando o método texts_to_sequences do objeto Tokenizer.\n",
    "\n",
    "Depois, cada setença é completada com o token de 'pad' ou truncada para que todas tenham o mesmo comprimento.\n",
    "\n",
    "Os parâmetros são:\n",
    "- maxlen: tamanho máximo de todas as sequências. O valor *default* é o comprimento da sentença mais longa.\n",
    "- padding: 'pre' ou 'post' (*default*). Completa com tokens 'pad' antes ('pre') ou depois ('post') de cada sequencia.\n",
    "- truncating: 'pre' ou 'post' (*default*). Se o tamanho de uma sentença for maior do que o valor de 'maxlen', ela será truncada para 'maxlen'. A opção 'pre' trunca no início e 'post' trunca no final da sequência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758dfcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Dados de treino\n",
    "training_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "training_padded = pad_sequences(training_sequences,\n",
    "                                maxlen = max_len,\n",
    "                                padding = padding_type,\n",
    "                                truncating = trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b109b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Dados de teste\n",
    "testing_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "testing_padded = pad_sequences(testing_sequences,\n",
    "                               maxlen = max_len,\n",
    "                               padding = padding_type,\n",
    "                               truncating = trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb794ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Formato dos tensores de treino e teste\n",
    "print('Shape of training tensor: ', training_padded.shape)\n",
    "print('Shape of testing tensor: ', testing_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração do Modelo de Classificação\n",
    "\n",
    "Define a arquitetura do modelo de classificação. O modelo usa uma Rede Neural Recorrente do tipo LSTM (Long Short Term Memory) Bidirecional.\n",
    "\n",
    "O modelo sequencial Keras permite a adição de camadas em uma sequência. Você deve adicionar as seguintes camadas em sequência:\n",
    "- Camada de Embedding, que mapeia cada palavra para um vetor N-dimensional de número reais. O 'embedding_dim' é o tamanho do vetor, nesse caso, 16. Como a camada de embedding é a primeira camada oculta do modelo, a camada de entrada deve ser definida por input_length = max_len.\n",
    "- Camada LSTM bidirecional, com 128 unidades.\n",
    "- Camada de Dropout com uma fração de drop = 0.2\n",
    "- Camada Densa (camada de classificação binária) com uma unidade e função de ativação sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf2f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16  #  tamanho do embedding (vetor) de palavras\n",
    "n_lstm = 128        #  número de unidades (dimensionalidade da saída)\n",
    "drop_lstm = 0.2     #  fração das unidades para drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf0a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,\n",
    "                    embedding_dim,\n",
    "                    input_length = max_len))\n",
    "# # #  INICIE O CÓDIGO AQUI # # #  (3 linhas de código)\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "# # #  TERMINE O CÓDIGO AQUI # # # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibe um sumário do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e653b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0675fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do Modelo\n",
    "\n",
    "Treina o modelo de classificação usando o método 'fit'.\n",
    "\n",
    "EarlyStopping (monitor='val_loss', patience=2) define que o método vai monitorar a perda nos dados de validação, e se a perda não for melhorada após 2 épocas, então o modelo de treinamento é finalizado. Essa técnica ajuda a evitar problemas de *overfitting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08169441",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "early_stop = EarlyStopping(monitor = 'val_loss',\n",
    "                           patience = 2)\n",
    "history = model.fit(training_padded,\n",
    "                    y_train,\n",
    "                    epochs = num_epochs,\n",
    "                    validation_data = (testing_padded, y_test),\n",
    "                    callbacks = [early_stop],\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plota gráficos de acurácia e perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae9fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ba093",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do Modelo\n",
    "\n",
    "Avalia o desempenho do modelo no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(testing_padded, y_test)\n",
    "print(f\"LSTM model loss: {test_loss} \" )\n",
    "print(f\"LSTM model accuracy: {test_acc*100:0.2f}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predição\n",
    "\n",
    "Prediz a saída de novas mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4eae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_msg = [\"Have friends and colleagues who could benefit from these weekly updates? Send them to this link to subscribe\",\n",
    "               \"Call me\",\"Get this subscription for free!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_spam(predict_msg):\n",
    "  new_seq = tokenizer.texts_to_sequences(predict_msg)\n",
    "  padded = pad_sequences(new_seq,\n",
    "                         maxlen = max_len,\n",
    "                         padding = padding_type,\n",
    "                         truncating = trunc_type)\n",
    "  return(model.predict(padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0557a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  'ham' se predict < 0.5 senão 'spam'\n",
    "predict_spam(predict_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 1\n",
    "\n",
    "Modifique a configuração do modelo de classificação de forma a usar três camadas de LSTM Bidirecional, em vez de apenas uma, como foi feito do código acima.\n",
    "\n",
    "Você vai precisar replicar todas as células do notebook, desde a Configuração do Modelo de Classificação, fazendo as devidas adaptações para a nova configuração.\n",
    "\n",
    "A saída esperada para o model.sumary() da nova arquitetura é:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicione abaixo a nova sequência de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #  INICIE O CÓDIGO AQUI # # #  (várias linhas de código / várias células)\n",
    "model = Sequential([Embedding(vocab_size, embedding_dim,input_length = max_len),\n",
    "                    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "                    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "                    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
    "                    tf.keras.layers.Dropout(0.2),\n",
    "                    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e6a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuração do Modelo de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8728fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0614cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "early_stop = EarlyStopping(monitor = 'val_loss',\n",
    "                           patience = 2)\n",
    "history = model.fit(training_padded,\n",
    "                    y_train,\n",
    "                    epochs = num_epochs,\n",
    "                    validation_data = (testing_padded, y_test),\n",
    "                    callbacks = [early_stop],\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2fdb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc92d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "triple_lstm_test_loss, triple_lstm_test_acc = model.evaluate(testing_padded, y_test)\n",
    "print(f\"LSTM model loss: {triple_lstm_test_loss} \" )\n",
    "print(f\"LSTM model accuracy: {triple_lstm_test_acc*100:0.2f}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b703bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_msg = [\"Have friends and colleagues who could benefit from these weekly updates? Send them to this link to subscribe\",\n",
    "               \"Call me\",\"Get this subscription for free!\"]\n",
    "\n",
    "#  'ham' se predict < 0.5 senão 'spam'\n",
    "predict_spam(predict_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3260ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #  TERMINE O CÓDIGO AQUI # # # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 2\n",
    "\n",
    "Modifique a configuração do modelo de classificação de forma a usar uma Gated Recurrent Unit (GRU) Bidirecional, em vez de uma LSTM.\n",
    "\n",
    "Você vai precisar replicar todas as células do notebook, desde a Configuração do Modelo de Classificação, fazendo as devidas adaptações para a nova configuração.\n",
    "\n",
    "A saída esperada para o model.sumary() da nova arquitetura é:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicione abaixo a nova sequência de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #  INICIE O CÓDIGO AQUI # # #  (várias linhas de código / várias células)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuração do Modelo de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28484cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_len),\n",
    "    Bidirectional(GRU(128)),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed27940",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ae6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f0fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "early_stop = EarlyStopping(monitor = 'val_loss',\n",
    "                           patience = 2)\n",
    "history = model.fit(training_padded,\n",
    "                    y_train,\n",
    "                    epochs = num_epochs,\n",
    "                    validation_data = (testing_padded, y_test),\n",
    "                    callbacks = [early_stop],\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3b9023",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fd06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_test_loss, gru_test_acc = model.evaluate(testing_padded, y_test)\n",
    "print(f\"LSTM model loss: {gru_test_loss} \" )\n",
    "print(f\"LSTM model accuracy: {gru_test_acc*100:0.2f}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d990d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_msg = [\"Have friends and colleagues who could benefit from these weekly updates? Send them to this link to subscribe\",\n",
    "               \"Call me\",\"Get this subscription for free!\"]\n",
    "\n",
    "#  'ham' se predict < 0.5 senão 'spam'\n",
    "predict_spam(predict_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a6223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #  TERMINE O CÓDIGO AQUI # # # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação dos Resultados\n",
    "\n",
    "Adicione abaixo uma tabela com a comparação dos resultados obtidos pelas três configurações efetuadas neste notebook.<br>\n",
    "Qual configuração obteve o melhor resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8904564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #  ADICIONE A TABELA DE RESULTADOS AQUI # # # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4feed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'Modelo': ['LSTM', 'Stacked LSTM (3 layers)', 'GRU'],\n",
    "    'Loss': [test_loss, triple_lstm_test_loss, gru_test_loss],\n",
    "    'Acurácia': [test_acc, triple_lstm_test_acc, gru_test_acc]\n",
    "}\n",
    "\n",
    "df_resultados = pd.DataFrame(results)\n",
    "\n",
    "df_resultados = df_resultados.sort_values(by='Acurácia', ascending=False)\n",
    "\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo LSTM de 3 camadas obteve a melhor acurácia, sendo 1,1% melhor que o modelo GRU. Entretanto, o modelo GRU apresenta menor custo computacional e o menor loss, o que pode ser positivo dependendo de sua aplicação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim\n",
    "\n",
    "Parabéns! Você efetuou todos os passos para criar modelos baseados em Redes Neurais Recorrentes para a tarefa de classificação de textos.\n",
    "\n",
    "-------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
